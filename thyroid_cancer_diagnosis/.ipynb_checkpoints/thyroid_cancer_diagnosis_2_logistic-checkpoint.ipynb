{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Machine Learning for Thyroid Cancer Diagnosis.\n",
    "##  Part 2: Logistic regression\n",
    "**The project was done with Rajiv Krishnakumar and Raghu Mahajan.**\n",
    "\n",
    "The essential goal was to predict thyroid cancer given gene expressions. A key hope is to definitively predict benign samples; this helps to avoid unnecessary surgeries, which often turn out to be much more problematic to a patient's health, than the thyroid cancer itself.\n",
    "\n",
    "\n",
    "- The data used here is pre-normalized, to mean zero and standard deviation 1. \n",
    "- The essentials of the data set are 265 patients whose biopsies were inconclusive, each with 173 reported gene expression levels. \n",
    "- There were a further 102 patients with 'conclusive' biopsies - i.e. a human determination of benign vs. malignant, to give 367 total patients.\n",
    "\n",
    "Here is an abstract from our final report:\n",
    "\n",
    "*We investigate the use of high throughput gene expression data in the diagnosis of thyroid cancers. Using logistic regression and support vector machines (SVMs), we develop a classifier which gives similar performance (89% sensitivity and 80% specificity) to the currently best- known classifier, but uses significantly fewer features. We used two different techniques, principal components analysis and mutual information score, to select features. The results do not depend significantly on which method is used for feature selection.*\n",
    "\n",
    "The breakdown of topics covered in each notebook is as follows:\n",
    "1. Data visualization, including PCA and tSNE visualizations.\n",
    "2. Logistic regression, discussing the use of feature selection via mutual information vs. use of different regularizers.\n",
    "3. SVMs with and without box constraints, and also using different kernel functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>163</th>\n",
       "      <th>164</th>\n",
       "      <th>165</th>\n",
       "      <th>166</th>\n",
       "      <th>167</th>\n",
       "      <th>168</th>\n",
       "      <th>169</th>\n",
       "      <th>170</th>\n",
       "      <th>171</th>\n",
       "      <th>172</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.17946</td>\n",
       "      <td>-0.92523</td>\n",
       "      <td>-0.69370</td>\n",
       "      <td>0.46983</td>\n",
       "      <td>-0.348710</td>\n",
       "      <td>-0.21465</td>\n",
       "      <td>-0.30662</td>\n",
       "      <td>1.35960</td>\n",
       "      <td>-0.50597</td>\n",
       "      <td>1.10310</td>\n",
       "      <td>...</td>\n",
       "      <td>0.068605</td>\n",
       "      <td>-0.53499</td>\n",
       "      <td>0.3080</td>\n",
       "      <td>-0.33358</td>\n",
       "      <td>0.82609</td>\n",
       "      <td>0.025969</td>\n",
       "      <td>-0.70057</td>\n",
       "      <td>-0.70648</td>\n",
       "      <td>0.46854</td>\n",
       "      <td>0.34735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.31370</td>\n",
       "      <td>-0.44796</td>\n",
       "      <td>0.12014</td>\n",
       "      <td>-0.64247</td>\n",
       "      <td>0.093455</td>\n",
       "      <td>-0.40658</td>\n",
       "      <td>-0.61403</td>\n",
       "      <td>-0.48841</td>\n",
       "      <td>0.77221</td>\n",
       "      <td>-0.68340</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.142500</td>\n",
       "      <td>2.13830</td>\n",
       "      <td>-1.0025</td>\n",
       "      <td>-1.21120</td>\n",
       "      <td>0.82492</td>\n",
       "      <td>-0.013805</td>\n",
       "      <td>0.79090</td>\n",
       "      <td>1.27370</td>\n",
       "      <td>0.92238</td>\n",
       "      <td>1.19300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.38540</td>\n",
       "      <td>1.07300</td>\n",
       "      <td>-1.03730</td>\n",
       "      <td>0.48228</td>\n",
       "      <td>0.501700</td>\n",
       "      <td>0.43634</td>\n",
       "      <td>0.77020</td>\n",
       "      <td>-0.13205</td>\n",
       "      <td>-1.65490</td>\n",
       "      <td>0.57408</td>\n",
       "      <td>...</td>\n",
       "      <td>0.162620</td>\n",
       "      <td>-0.12682</td>\n",
       "      <td>1.5029</td>\n",
       "      <td>0.82987</td>\n",
       "      <td>-0.71825</td>\n",
       "      <td>0.016890</td>\n",
       "      <td>-0.73851</td>\n",
       "      <td>-0.68747</td>\n",
       "      <td>-1.05070</td>\n",
       "      <td>-0.87795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.20878</td>\n",
       "      <td>0.16227</td>\n",
       "      <td>1.00610</td>\n",
       "      <td>-0.49424</td>\n",
       "      <td>-0.360830</td>\n",
       "      <td>0.67324</td>\n",
       "      <td>-0.11529</td>\n",
       "      <td>0.80011</td>\n",
       "      <td>-1.14330</td>\n",
       "      <td>0.74535</td>\n",
       "      <td>...</td>\n",
       "      <td>0.278480</td>\n",
       "      <td>-1.07120</td>\n",
       "      <td>-1.5862</td>\n",
       "      <td>0.30024</td>\n",
       "      <td>0.25210</td>\n",
       "      <td>0.831140</td>\n",
       "      <td>2.35430</td>\n",
       "      <td>-0.86967</td>\n",
       "      <td>-0.17322</td>\n",
       "      <td>-0.45560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-2.51940</td>\n",
       "      <td>-0.60297</td>\n",
       "      <td>-1.46150</td>\n",
       "      <td>1.31050</td>\n",
       "      <td>-1.264400</td>\n",
       "      <td>-0.77405</td>\n",
       "      <td>-0.18420</td>\n",
       "      <td>-1.05920</td>\n",
       "      <td>-1.12240</td>\n",
       "      <td>-1.93630</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.014778</td>\n",
       "      <td>-0.73844</td>\n",
       "      <td>1.3451</td>\n",
       "      <td>0.70413</td>\n",
       "      <td>-3.20790</td>\n",
       "      <td>-2.959900</td>\n",
       "      <td>-0.53812</td>\n",
       "      <td>-0.66792</td>\n",
       "      <td>-3.29540</td>\n",
       "      <td>-3.41680</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 173 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       0        1        2        3         4        5        6        7    \\\n",
       "0  0.17946 -0.92523 -0.69370  0.46983 -0.348710 -0.21465 -0.30662  1.35960   \n",
       "1  1.31370 -0.44796  0.12014 -0.64247  0.093455 -0.40658 -0.61403 -0.48841   \n",
       "2 -0.38540  1.07300 -1.03730  0.48228  0.501700  0.43634  0.77020 -0.13205   \n",
       "3 -0.20878  0.16227  1.00610 -0.49424 -0.360830  0.67324 -0.11529  0.80011   \n",
       "4 -2.51940 -0.60297 -1.46150  1.31050 -1.264400 -0.77405 -0.18420 -1.05920   \n",
       "\n",
       "       8        9     ...          163      164     165      166      167  \\\n",
       "0 -0.50597  1.10310   ...     0.068605 -0.53499  0.3080 -0.33358  0.82609   \n",
       "1  0.77221 -0.68340   ...    -1.142500  2.13830 -1.0025 -1.21120  0.82492   \n",
       "2 -1.65490  0.57408   ...     0.162620 -0.12682  1.5029  0.82987 -0.71825   \n",
       "3 -1.14330  0.74535   ...     0.278480 -1.07120 -1.5862  0.30024  0.25210   \n",
       "4 -1.12240 -1.93630   ...    -0.014778 -0.73844  1.3451  0.70413 -3.20790   \n",
       "\n",
       "        168      169      170      171      172  \n",
       "0  0.025969 -0.70057 -0.70648  0.46854  0.34735  \n",
       "1 -0.013805  0.79090  1.27370  0.92238  1.19300  \n",
       "2  0.016890 -0.73851 -0.68747 -1.05070 -0.87795  \n",
       "3  0.831140  2.35430 -0.86967 -0.17322 -0.45560  \n",
       "4 -2.959900 -0.53812 -0.66792 -3.29540 -3.41680  \n",
       "\n",
       "[5 rows x 173 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#As usual import some modules and import the dataset\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "#import the data and look at it\n",
    "X = pd.read_csv(\"data/normalized_data_265.csv\", header =None)\n",
    "y = pd.read_csv(\"data/outcome_265.csv\", header = None)\n",
    "\n",
    "\n",
    "X_full = pd.read_csv(\"data/normalized_data_367.csv\", header =None)\n",
    "y_full = pd.read_csv(\"data/outcome_367.csv\", header = None)\n",
    "\n",
    "#Look at the first few rows\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train-Test-Validation split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(212, 173)\n",
      "(212,)\n",
      "(53, 173)\n",
      "(53,)\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic regression \n",
    "\n",
    "A simple and straightforward first pass is always a logistic regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy:  1.0\n",
      "Test set accuracy:  0.754716981132\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "\n",
    "#First perform a train-test split\n",
    "X = X.as_matrix()\n",
    "y = y.as_matrix().reshape(len(y))\n",
    "X_full = X_full.as_matrix()\n",
    "y_full = y_full.as_matrix().reshape(len(y_full))\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2)\n",
    "\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "logit_bare = LogisticRegression(random_state = 1, solver = 'liblinear')\n",
    "logit_bare.fit(X_train, y_train)\n",
    "\n",
    "print \"Training accuracy: \",logit_bare.score(X_train,y_train)\n",
    "print \"Test set accuracy: \",logit_bare.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
